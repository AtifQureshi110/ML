# ML Algorithms.
All Models of ML
# Linear Regression
Linear Regression works on continuous data, aiming to find a relationship between independent (predictor) and dependent (target) variables by modeling their relationship with a linear equation. Its goal is to minimize the errors and fit a line (or hyperplane) that best represents the data.

1. Purpose:
   
Linear Regression is used to model the relationship between an independent variable (or variables) and a dependent variable.
It predicts continuous values based on this relationship.

2. How It Works:

It attempts to find the best-fitting straight line (in the case of simple linear regression) or a hyperplane (in the case of multiple linear regression) that minimizes the error between the predicted and actual values.
The relationship is expressed as a linear equation:
𝑦 = 𝛽0 + 𝛽1𝑥 + 𝜖
y: Dependent variable (target).
x: Independent variable (predictor).
𝛽0: Intercept.
β1: Slope of the line.
ϵ: Error term (residual).

3. Bringing Points Near the Line:

Linear Regression uses the least squares method to minimize the sum of the squared differences (errors) between the observed and predicted values. This process ensures that the predicted line is as close to the actual data points as possible.
